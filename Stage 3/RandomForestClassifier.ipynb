{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"Python Spark RF Classifier\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load and parse the data file,converitn it to a DataFrame\n",
    "#path='hdfs://soit-hdp-pro-1.ucc.usyd.edu.au/share/MNIST/'\n",
    "path='../Data/'\n",
    "training_data=spark.read.csv(path+'Train-label-28x28.csv', header=False, inferSchema=\"true\").withColumnRenamed('_c0','label')\n",
    "testing_data=spark.read.csv(path+'Test-label-28x28.csv',header=False, inferSchema=\"true\").withColumnRenamed('_c0','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+\n",
      "|label|            features| ID|\n",
      "+-----+--------------------+---+\n",
      "|    5|(784,[152,153,154...|  0|\n",
      "|    0|(784,[127,128,129...|  1|\n",
      "|    4|(784,[160,161,162...|  2|\n",
      "|    1|(784,[158,159,160...|  3|\n",
      "|    9|(784,[208,209,210...|  4|\n",
      "+-----+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 60000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "#Train Data\n",
    "assembler=VectorAssembler(inputCols=training_data.columns[1:],outputCol='features')\n",
    "newdata=assembler.transform(training_data)\n",
    "train_data=newdata.select('label','features')\n",
    "train_id = train_data.withColumn(\n",
    "        '{}_id'.format(train_data), monotonically_increasing_id())\n",
    "training=train_id.withColumnRenamed('DataFrame[label: int, features: vector]_id','ID')\n",
    "training.show(5), training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+\n",
      "|label|            features| ID|\n",
      "+-----+--------------------+---+\n",
      "|    7|(784,[202,203,204...|  0|\n",
      "|    2|(784,[94,95,96,97...|  1|\n",
      "|    1|(784,[128,129,130...|  2|\n",
      "|    0|(784,[124,125,126...|  3|\n",
      "|    4|(784,[150,151,159...|  4|\n",
      "+-----+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 10000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data\n",
    "assembler_test=VectorAssembler(inputCols=testing_data.columns[1:],outputCol='features')\n",
    "newdata_test=assembler_test.transform(testing_data)\n",
    "test_data=newdata_test.select('label','features')\n",
    "test_id = test_data.withColumn(\n",
    "        '{}_id'.format(test_data), monotonically_increasing_id())\n",
    "testing=test_id.withColumnRenamed('DataFrame[label: int, features: vector]_id','ID')\n",
    "testing.show(5), testing.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+\n",
      "|label|             feature| ID|\n",
      "+-----+--------------------+---+\n",
      "|    5|[880.731433034386...|  0|\n",
      "|    0|[1768.51722024166...|  1|\n",
      "|    4|[704.949236329314...|  2|\n",
      "|    1|[-42.328192193772...|  3|\n",
      "|    9|[374.043902028332...|  4|\n",
      "+-----+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#apply PCA\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "\n",
    "pca = PCA(k=100, inputCol=\"features\", outputCol=\"feature\")\n",
    "pca_train = pca.fit(training)\n",
    "\n",
    "#Apply PCA to train / test features\n",
    "train_pca = pca_train.transform(training).select(\"label\",\"feature\",\"ID\")\n",
    "test_pca = pca_train.transform(testing).select(\"label\",\"feature\",\"ID\")\n",
    "train_pca.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 ms, sys: 5.38 ms, total: 20.3 ms\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#build up random forest model and train model\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"feature\", numTrees=10)\n",
    "model=rf.fit(train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 ms, sys: 4.82 ms, total: 17.6 ms\n",
      "Wall time: 70 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Make predictions.\n",
    "predictions = model.transform(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+--------------------+----------+\n",
      "|label|             feature| ID|         probability|prediction|\n",
      "+-----+--------------------+---+--------------------+----------+\n",
      "|    7|[424.527675108320...|  0|[0.05015182897710...|       7.0|\n",
      "|    2|[777.495806467954...|  1|[0.05624565191437...|       6.0|\n",
      "|    1|[-189.22802355912...|  2|[0.08565436069946...|       1.0|\n",
      "|    0|[1990.70583089721...|  3|[0.27157347072812...|       0.0|\n",
      "|    4|[946.077017433915...|  4|[0.03172361638453...|       4.0|\n",
      "|    1|[-264.46945985278...|  5|[0.09749006756645...|       1.0|\n",
      "|    4|[502.087335041735...|  6|[0.05443274314664...|       4.0|\n",
      "|    9|[438.703086461166...|  7|[0.05737224402671...|       8.0|\n",
      "|    5|[1019.13380549721...|  8|[0.05695701216925...|       2.0|\n",
      "|    9|[725.804171346720...|  9|[0.02989357614245...|       9.0|\n",
      "|    0|[1882.34258754238...| 10|[0.50891900760012...|       0.0|\n",
      "|    6|[1091.09610327598...| 11|[0.08565696476486...|       6.0|\n",
      "|    9|[587.861814723699...| 12|[0.10326664226726...|       9.0|\n",
      "|    0|[1806.12591709845...| 13|[0.29477942723453...|       0.0|\n",
      "|    1|[-121.37713905835...| 14|[0.08756548110614...|       1.0|\n",
      "|    5|[867.896344990283...| 15|[0.06803567408975...|       5.0|\n",
      "|    9|[929.963113523381...| 16|[0.04913771248203...|       4.0|\n",
      "|    7|[740.036902004868...| 17|[0.06841850842544...|       7.0|\n",
      "|    3|[835.686403402641...| 18|[0.04079926112539...|       6.0|\n",
      "|    4|[514.838416853079...| 19|[0.05277892520995...|       4.0|\n",
      "+-----+--------------------+---+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select('label','feature','ID','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7649\n",
      "Test Error = 0.2351\n",
      "CPU times: user 4.9 ms, sys: 3.37 ms, total: 8.27 ms\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "\n",
    "# rfModel = model.stages[2]\n",
    "# print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=0, label=5, feature=DenseVector([880.7314, 329.9508, 197.6063, 1022.2037, 893.9353, 129.5378, 739.8278, 117.8132, -63.2179, -279.9267, 300.5174, -83.6115, 103.9882, 847.0763, 125.9195, 61.0834, -186.1493, 143.2418, -329.0186, 155.5136, 18.0902, -49.9165, 190.4536, 210.3358, 72.0857, -122.5584, 344.546, -162.1976, -131.0344, -132.7735, -82.9295, -46.1306, 120.4762, -33.7134, -142.8575, 179.0475, -62.1566, 203.2188, 152.7653, 344.4394, 203.9445, 161.9635, -8.4977, -91.7776, -141.3525, 15.1394, 134.7349, 67.0336, 14.7887, 37.6015, -97.6008, -127.4233, 122.8006, 42.2424, -13.1368, 176.1595, -144.1529, -45.6747, 154.3456, -122.5431, -83.4824, -4.0127, -86.0823, 89.5746, -175.2869, 140.876, 200.0559, -40.1264, -60.6752, -18.5383, -94.0646, 122.8287, -55.0722, 2.6127, -107.8599, 66.5914, -56.8551, -35.9199, 31.5544, -41.7844, -91.704, -26.7733, 26.6456, 55.6154, -34.5123, 10.4143, -164.1281, -39.9939, -47.0297, -20.3422, 30.9545, 39.0317, 58.4083, -78.3126, 20.5267, 60.4895, 49.6808, 15.1545, 30.2016, 132.4656]), label=7, feature=DenseVector([424.5277, -730.5222, 179.2756, 777.6196, 425.8708, -345.3109, 898.7382, 428.7594, -27.4878, 104.6313, 297.9047, 59.9869, -43.0493, -122.371, -231.3658, -14.3027, -146.4749, 89.414, -123.7011, 46.3869, -62.5745, 259.5283, -78.2594, -122.3114, -102.2687, 18.6292, -99.0931, 36.5025, 13.329, -221.9831, 93.7317, 284.3131, 95.1088, 204.8764, -14.7102, 152.582, 95.8835, -103.5235, 30.2718, -92.7304, -271.9503, 84.3579, 142.093, -47.1598, -185.6514, -27.2196, 101.4059, 49.6436, -26.9869, -97.4456, 29.4351, -178.9548, 36.5198, -144.9845, 96.9951, 10.0271, -79.4497, 81.7203, 3.5276, -142.3206, 33.4628, 97.4648, -54.6103, -34.8137, -36.931, -22.0231, -51.8189, -34.0572, -135.2275, -38.4947, 28.8417, -144.0837, -36.1836, -84.5619, -119.266, 111.4061, -14.9864, 96.4964, -100.458, 75.5074, -27.6739, -24.3343, 61.8726, -21.931, -93.6972, 7.0657, -24.8931, -63.3996, -18.0466, -51.5501, 23.3662, -14.6521, 105.7389, 30.7044, -15.0702, 4.8804, 59.2512, 75.3112, 22.9488, 27.8388]), rawPrediction=DenseVector([0.5015, 0.056, 0.2516, 0.7112, 0.7555, 0.3885, 0.4061, 5.4325, 0.3134, 1.1836]), probability=DenseVector([0.0502, 0.0056, 0.0252, 0.0711, 0.0755, 0.0389, 0.0406, 0.5432, 0.0313, 0.1184]), prediction=7.0)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pca.join(predictions, 'ID').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "def prepare_data(actual_data, prediction_data, on='ID'):\n",
    "    return actual_data.join(prediction_data, on).rdd \\\n",
    "        .map(lambda x: (float(x.prediction), float(x.label)))\n",
    "\n",
    "\n",
    "def overall_report(actual_data, prediction_data):\n",
    "    # Calculate actual / predicted labels in rdd from\n",
    "    prediction_and_labels = prepare_data(actual_data, prediction_data)\n",
    "\n",
    "    # Calculate actual / predicted labels in rdd from\n",
    "    metrics = MulticlassMetrics(prediction_and_labels)\n",
    "\n",
    "    # Calculate overall level metrics\n",
    "    # print('Precision:', metrics.precision(), type(metrics.precision()))\n",
    "    # return sc.parallelize([(Vectors.dense(metrics.accuracy),\n",
    "    #                         Vectors.dense(metrics.precision()),\n",
    "    #                         Vectors.dense(metrics.recall()),\n",
    "    #                         Vectors.dense(metrics.fMeasure()))]).toDF(['Accuracy', 'Precision', 'Recall', 'F - Score'])\n",
    "    print('Accuracy\\tPrecision\\tRecall\\tF-Score')\n",
    "    print('{}\\t{}\\t{}\\t{}'.format(metrics.accuracy, metrics.precision(),\n",
    "                                  metrics.recall(), metrics.fMeasure()))\n",
    "\n",
    "\n",
    "def classification_report(actual_data, prediction_data):\n",
    "    # Calculate actual / predicted labels in rdd from\n",
    "    prediction_and_labels = prepare_data(actual_data, prediction_data)\n",
    "\n",
    "    # Calculate calculate class level metrics\n",
    "    metrics = MulticlassMetrics(prediction_and_labels)\n",
    "    classes = set(actual_data.rdd.map(lambda x: float(x.label)).collect())\n",
    "    print('Class\\tPrecision\\tRecall\\tF-Score')\n",
    "    for c in sorted(classes):\n",
    "        print('{}\\t{}\\t{}\\t{}'.format(c,\n",
    "                                      round(metrics.precision(c), 3),\n",
    "                                      round(metrics.recall(c), 3),\n",
    "                                      round(metrics.fMeasure(c), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\tPrecision\tRecall\tF-Score\n",
      "0.7649\t0.7649\t0.7649\t0.7649\n"
     ]
    }
   ],
   "source": [
    "#print out precision, recall, f1-score\n",
    "overall_report(test_pca, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\tPrecision\tRecall\tF-Score\n",
      "0.0\t0.841\t0.74\t0.787\n",
      "1.0\t0.863\t0.952\t0.906\n",
      "2.0\t0.746\t0.764\t0.755\n",
      "3.0\t0.68\t0.794\t0.733\n",
      "4.0\t0.797\t0.69\t0.74\n",
      "5.0\t0.784\t0.525\t0.629\n",
      "6.0\t0.783\t0.909\t0.842\n",
      "7.0\t0.765\t0.813\t0.788\n",
      "8.0\t0.657\t0.73\t0.692\n",
      "9.0\t0.752\t0.683\t0.716\n"
     ]
    }
   ],
   "source": [
    "# print out precision, recall, f1-score for each class\n",
    "classification_report = classification_report(test_pca, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
