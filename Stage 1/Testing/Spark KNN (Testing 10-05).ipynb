{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark KNN (Testing 10-05)\n",
    "\n",
    "Visit PySparkShell at: <a>http://localhost:4040/jobs/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up spark context\n",
    "\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .appName(\"Python Spark KNN Test\") \\\n",
    "#     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "from math import sqrt\n",
    "# from pyspark.sql.functions import sqrt\n",
    "\n",
    "# Data\n",
    "train_features = spark.read.csv('../Data/Train-28x28.csv', header=False, inferSchema=\"true\")\n",
    "test_features = spark.read.csv('../Data/Test-28x28.csv', header=False, inferSchema=\"true\")\n",
    "train_labels = spark.read.csv('../Data/Train-label.csv', header=False, inferSchema=\"true\")\n",
    "test_labels = spark.read.csv('../Data/Test-label.csv', header=False, inferSchema=\"true\")\n",
    "\n",
    "def get_vector(data, col_name):\n",
    "    assembler = VectorAssembler(inputCols=data.columns, outputCol=col_name)\n",
    "    return assembler.transform(data).select(col_name)    \n",
    "\n",
    "# Vectors\n",
    "train_features = get_vector(train_features, 'features')\n",
    "test_features = get_vector(test_features, 'features')\n",
    "train_labels = get_vector(train_labels, 'train_labels')\n",
    "test_labels = get_vector(test_labels, 'test_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "pca = PCA(k=153, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "pca_model = pca.fit(train_features)\n",
    "\n",
    "# Apply PCA to train / test features\n",
    "train_features_pca = pca_model.transform(train_features).select(\"pca_features\")\n",
    "test_features_pca = pca_model.transform(test_features).select(\"pca_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename pca feature column values\n",
    "train_features_pca = train_features_pca.withColumnRenamed(\"pca_features\", \"train_features\")\n",
    "test_features_pca = test_features_pca.withColumnRenamed(\"pca_features\", \"test_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop a combined dataframe for all data\n",
    "\n",
    "def combine_features_labels(feature_vector, label_vector, kind='train'):\n",
    "    features = feature_vector.withColumn('{}_id'.format(kind), monotonically_increasing_id())\n",
    "    labels = label_vector.withColumn('{}_id'.format(kind), monotonically_increasing_id())\n",
    "    data = features.join(labels, '{}_id'.format(kind))\n",
    "    return data\n",
    "\n",
    "# Create combined train / test data\n",
    "train_data = combine_features_labels(train_features_pca, train_labels, 'train')\n",
    "test_data = combine_features_labels(test_features_pca, test_labels, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------------+\n",
      "|train_id|      train_features|train_labels|\n",
      "+--------+--------------------+------------+\n",
      "|       0|[880.731433034388...|       [5.0]|\n",
      "|       1|[1768.51722024166...|       [0.0]|\n",
      "|       2|[704.949236329314...|       [4.0]|\n",
      "|       3|[-42.328192193770...|       [1.0]|\n",
      "|       4|[374.043902028336...|       [9.0]|\n",
      "+--------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+-----------+\n",
      "|test_id|       test_features|test_labels|\n",
      "+-------+--------------------+-----------+\n",
      "|      0|[424.527675108323...|      [7.0]|\n",
      "|      1|[777.495806467955...|      [2.0]|\n",
      "|      2|[-189.22802355912...|      [1.0]|\n",
      "|      3|[1990.70583089721...|      [0.0]|\n",
      "|      4|[946.077017433917...|      [4.0]|\n",
      "+-------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, 15558, 3105)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.show(5), test_data.show(5), train_data.count(), test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+--------+--------------------+------------+\n",
      "|test_id|       test_features|test_labels|train_id|      train_features|train_labels|\n",
      "+-------+--------------------+-----------+--------+--------------------+------------+\n",
      "|      0|[424.527675108323...|      [7.0]|       0|[880.731433034388...|       [5.0]|\n",
      "|      0|[424.527675108323...|      [7.0]|       1|[1768.51722024166...|       [0.0]|\n",
      "|      0|[424.527675108323...|      [7.0]|       2|[704.949236329314...|       [4.0]|\n",
      "|      0|[424.527675108323...|      [7.0]|       3|[-42.328192193770...|       [1.0]|\n",
      "|      0|[424.527675108323...|      [7.0]|       4|[374.043902028336...|       [9.0]|\n",
      "+-------+--------------------+-----------+--------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 48307590)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate cross-join => every training example is repeated for every test example; \n",
    "# e.g. 4 train examples and 2 test examples produce 4 * 2 = 8 new rows\n",
    "cross = test_data.crossJoin(train_data)\n",
    "cross.show(5), cross.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def cosine_distance(vector_one, vector_two):\n",
    "    dot_product = vector_one.dot(vector_two)\n",
    "    sum_sq_vector_one = sqrt(vector_one.dot(vector_one))\n",
    "    sum_sq_vector_two = sqrt(vector_two.dot(vector_two))\n",
    "    return float(dot_product / (sum_sq_vector_one * sum_sq_vector_two))\n",
    "\n",
    "# find cosine distance between each train and test features set in each row\n",
    "distance = cross.rdd \\\n",
    "            .map(lambda x: (x.test_id, (cosine_distance(x.train_features, x.test_features), x.train_labels[0]))) \\\n",
    "#             .collect()\n",
    "\n",
    "# Output in the form (test_id, (distance, train_label))\n",
    "\n",
    "# Output looks like:\n",
    "#\n",
    "# [(0, (0.4354039832219311, 5.0)),\n",
    "#  (1, (0.350220604260178, 5.0)),\n",
    "#  (2, (0.36093373903217113, 5.0)),\n",
    "#  (3, (0.5668560199651423, 5.0)), \n",
    "#  ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Group all values by key ie. the test_id and take the K nearest neighbors\n",
    "\n",
    "K = 15\n",
    "\n",
    "def majority_vote(neighbors):\n",
    "    closest_instance = neighbors[0][1]\n",
    "    votes = [n[1] for n in neighbors]\n",
    "    counted_votes = Counter(votes)\n",
    "    most_common_vote = counted_votes.most_common(1)[0]\n",
    "    if most_common_vote[1] > 1:\n",
    "        return float(most_common_vote[0])\n",
    "    else:\n",
    "        return float(closest_instance)\n",
    "\n",
    "predictions = distance \\\n",
    "                .groupByKey() \\\n",
    "                .map(lambda x: (x[0], majority_vote(sorted(list(x[1]))[:K]))) \\\n",
    "                .collect()\n",
    "            \n",
    "# Output in the form (test_id, prediction)\n",
    "\n",
    "# Output looks like:\n",
    "#\n",
    "# [(0, 1.0),\n",
    "#  (1, 4.0),\n",
    "#  (2, 4.0),\n",
    "#  (3, 1.0),\n",
    "#  (4, 1.0),\n",
    "#  (5, 4.0),\n",
    "#  (6, 1.0), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert predictions to dataframe\n",
    "\n",
    "prediction_data = sc.parallelize(predictions).toDF(['test_id', 'prediction'])\n",
    "prediction_data.show(5), prediction_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find accuracy\n",
    "\n",
    "accuracy = test_data.join(prediction_data, 'test_id').rdd \\\n",
    "            .map(lambda x: x.test_labels[0] == x.prediction) \\\n",
    "            .filter(lambda x : x == True).count() \\\n",
    "            / test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
